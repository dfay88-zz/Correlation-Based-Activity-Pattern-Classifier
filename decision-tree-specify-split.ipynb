{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from dbfread import DBF\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import _tree\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "idap_dbf = DBF('R:/Projects/20713A_Ohio3C/HIS/IDAP.dbf')\n",
    "idap = pd.DataFrame(iter(idap_dbf))\n",
    "\n",
    "hhtype_dbf = DBF('R:/Projects/20713A_Ohio3C/HIS/hhtype.dbf')\n",
    "hhtype = pd.DataFrame(iter(hhtype_dbf))\n",
    "\n",
    "pertype_dbf = DBF('R:/Projects/20713A_Ohio3C/HIS/PERTYPE.dbf')\n",
    "pertype = pd.DataFrame(iter(pertype_dbf))\n",
    "\n",
    "accessibility_dbf = DBF('R:/Projects/20713A_Ohio3C/Accessibility/ACCESSIBILITY_MEASURES.dbf')\n",
    "accessibility = pd.DataFrame(iter(accessibility_dbf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process IDAP Data\n",
    "idap = idap[idap['MPO'] == 1]\n",
    "    \n",
    "genders = {1:'Male', 2:'Female'}\n",
    "pertypes = {1:'FT_Worker', 2:'PT_Worker', 3:'Univ_Stud', 4:'Non_Worker', 5:'Retiree', 6:'DA_Stud', 7:'PDA_Stud', 8:'PreSch_Child'}\n",
    "idaps = {1:'M', 2:'NM', 3:'H'}\n",
    "\n",
    "idap['GENDER'] = idap.GENDER.map(genders)\n",
    "idap['PERTYPE'] = idap.PERTYPE.map(pertypes)\n",
    "idap['IDAP'] = idap.IDAP.map(idaps)\n",
    "idap.age = idap.AGE.astype(int)\n",
    "\n",
    "idap = idap[['SAMPN', 'PERNO', 'GENDER', 'PERTYPE', 'AGE', 'IDAP']]\n",
    "idap.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process household type data\n",
    "hhtype = hhtype[hhtype['MPO'] == 1]\n",
    "\n",
    "incomes = {1: '$49,999 or less', 2: '$49,999 or less', 3: '$50,000 to $74,999', 4: '$75,000 or more', \\\n",
    "           5: '$75,000 or more', 9: 'DK/RF'}\n",
    "hhtype['HINCCAT1'] = hhtype.HINCCAT1.map(incomes)\n",
    "hhtype['HWORK_F'] = hhtype['HWORK_F'].fillna(0)\n",
    "hhtype['HWORK_P'] = hhtype['HWORK_P'].fillna(0)\n",
    "hhtype['WORKERS'] = hhtype['HWORK_F'] + hhtype['HWORK_P']\n",
    "           \n",
    "    \n",
    "# Calculate car sufficiency\n",
    "car_sufficiency = []\n",
    "for ix, row in hhtype.iterrows():\n",
    "    if row['HHVEH'] == 0:\n",
    "        car_sufficiency.append('Zero Cars')\n",
    "    elif row['HHVEH'] < row['WORKERS']:\n",
    "        car_sufficiency.append('Fewer Cars than Workers')\n",
    "    elif row['HHVEH'] == row['WORKERS']:\n",
    "        car_sufficiency.append('Cars Equals to Workers')\n",
    "    elif row['HHVEH'] > row['WORKERS']:\n",
    "        car_sufficiency.append('More Cars than Workers')\n",
    "        \n",
    "hhtype['CAR_SUFF'] = car_sufficiency\n",
    "\n",
    "\n",
    "hh_features = hhtype[['SAMPN', 'CAR_SUFF', 'HINCCAT1', 'HHTAZ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process person type data\n",
    "pertype = pertype[pertype['MPO'] == 1]\n",
    "educations = {1: 'Less than Bachelors', 2: 'Less than Bachelors', 3: 'Less than Bachelors', \\\n",
    "              4: 'Less than Bachelors', 5: 'Bachelors or Higher Degree', 6: 'Bachelors or Higher Degree', \\\n",
    "              7: 'Less than Bachelors', 99: 'DK/RF'}\n",
    "\n",
    "numjobs = {0: 'No Job', 1: 'More than One Job', 2: 'One Job', 99: 'DK/RF'}\n",
    "jobtypes = {1: 'Agriculture and Mining', 2: 'Transportation, Utilities and Warehousing', \\\n",
    "            3: 'Manufacturing and Wholesale Trade', 5: 'Information, Professor/Scientist, Management, Admin', \\\n",
    "            6: 'Education', 7: 'Finance & Real Estate', 8: 'Arts/Entertainment', 9: 'Public Admin', \\\n",
    "            10: 'Health', 11: 'Other', 12: 'MORPC INDUS=80', 13: 'Retail'}\n",
    "\n",
    "\n",
    "pertype.EDUCA = pertype.EDUCA.map(educations)\n",
    "pertype.JOBS = pertype.JOBS.map(numjobs)\n",
    "pertype.JOBTYPE = pertype.JOBTYPE.map(jobtypes)\n",
    "pertype.JOBTYPE = pertype.JOBTYPE.fillna('No Job Type')\n",
    "per_features = pertype[['SAMPN', 'PERNO', 'EDUCA', 'JOBS', 'JOBTYPE', 'WU_DIST', 'SU_DIST']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process accessibility data\n",
    "accessibility = accessibility[accessibility['MPO'] == 1]\n",
    "access_features = accessibility[['TAZ', 'ACCESS7', 'ACCESS8', 'ACCESS9']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idap.reset_index(inplace=True)\n",
    "idap['PERID'] = idap['SAMPN'].astype(str) + idap['PERNO'].astype(str)\n",
    "per_features['PERID'] = per_features['SAMPN'].astype(str) + per_features['PERNO'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge household data\n",
    "features = pd.merge(idap, hh_features, on='SAMPN', how='inner')\n",
    "features = pd.merge(features, per_features.drop(['SAMPN','PERNO'],axis=1), on='PERID', how='inner')\n",
    "features = pd.merge(features, access_features, left_on='HHTAZ', right_on='TAZ', how='left')\n",
    "features.drop(['TAZ', 'HHTAZ', 'index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign accessibilities\n",
    "accessibility = []\n",
    "for ix, row in features.iterrows():\n",
    "    if row['CAR_SUFF'] == 'Zero Cars':\n",
    "        accessibility.append(row['ACCESS7'] + 1)\n",
    "    elif row['CAR_SUFF'] == 'Fewer Cars Than Workers':\n",
    "        accessibility.append(row['ACCESS8'] + 1)\n",
    "    else:\n",
    "        accessibility.append(row['ACCESS9'] + 1)\n",
    "features['ACCESSIBILITY'] = np.log(accessibility)\n",
    "features.drop(['ACCESS7', 'ACCESS8', 'ACCESS9'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign work or school distance based on person type\n",
    "distances = []\n",
    "for ix, row in features.iterrows():\n",
    "    if( row['PERTYPE'] == 'FT_Worker') or (row['PERTYPE'] == 'PT_Worker'):\n",
    "        distances.append(row['WU_DIST'])\n",
    "    elif (row['PERTYPE'] == 'DA_Stud') or (row['PERTYPE'] == 'PDA_Stud') or (row['PERTYPE'] == 'Univ_Stud'):\n",
    "        distances.append(row['SU_DIST'])\n",
    "    elif row['WU_DIST'] > 0:\n",
    "        distances.append(row['WU_DIST'])\n",
    "    elif row['SU_DIST'] > 0:\n",
    "        distances.append(row['SU_DIST'])\n",
    "    else:\n",
    "        distances.append(999)\n",
    "        \n",
    "features['DIST'] = distances\n",
    "features.drop(['WU_DIST', 'SU_DIST', 'PERID'], axis=1, inplace=True)\n",
    "features.set_index('SAMPN', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_interactions_columns = ['Retiree_NM', 'Retiree_M', 'Retiree_H', 'FT_Worker_NM', 'FT_Worker_M', 'FT_Worker_H', \\\n",
    "                           'PT_Worker_NM', 'PT_Worker_M', 'PT_Worker_H', 'DA_Stud_NM', 'DA_Stud_M', 'DA_Stud_H', \\\n",
    "                           'PreSch_Child_NM', 'PreSch_Child_M', 'PreSch_Child_H', 'PDA_Stud_NM', 'PDA_Stud_M', 'PDA_Stud_H', \\\n",
    "                           'Non_Worker_NM', 'Non_Worker_M', 'Non_Worker_H', 'Univ_Stud_NM', 'Univ_Stud_M', 'Univ_Stud_H']\n",
    "\n",
    "hh_interactions = pd.DataFrame(index=[list(itertools.product(features.PERTYPE.unique(), features.IDAP.unique()))])\n",
    "hh_interactions.reset_index(inplace=True)\n",
    "hh_interactions.columns = ['PERTYPE', 'IDAP']\n",
    "hh_interactions_final = pd.DataFrame()\n",
    "for ix, row in features.iterrows():\n",
    "    df = pd.DataFrame(features.loc[ix])\n",
    "    if len(df.T) == 1:\n",
    "        temp = [0]*24\n",
    "        hh_interactions_final = hh_interactions_final.append(pd.Series(temp), ignore_index=True)\n",
    "    else:\n",
    "        df = df.groupby(['PERTYPE', 'IDAP']).count()\n",
    "        df = df[['PERNO']]\n",
    "        df.columns = ['COUNT']\n",
    "        df.reset_index(inplace=True)\n",
    "        hh_interactions_temp = pd.merge(hh_interactions, df, how='left', on=['PERTYPE', 'IDAP'])\n",
    "        hh_interactions_temp.loc[(hh_interactions_temp.PERTYPE == row['PERTYPE']) & \\\n",
    "                                 (hh_interactions_temp.IDAP == row['IDAP']), 'COUNT'] = hh_interactions_temp.loc[(hh_interactions_temp.PERTYPE == row['PERTYPE']) & \\\n",
    "                                                                                                         (hh_interactions_temp.IDAP == row['IDAP']), 'COUNT'] - 1\n",
    "        hh_interactions_final = hh_interactions_final.append(hh_interactions_temp['COUNT'].T)\n",
    "hh_interactions_final.fillna(0, inplace=True)\n",
    "hh_interactions_final.columns = hh_interactions_columns\n",
    "features.reset_index(inplace=True)\n",
    "features = pd.concat([features, hh_interactions_final], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix age for pre-drivng age students\n",
    "features.loc[(features.PERTYPE == 'PDA_Stud') & (features.AGE > 18), 'AGE'] = 12\n",
    "features.loc[(features.PERTYPE == 'PreSch_Child') & (features.AGE > 10), 'AGE'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define x, y split function\n",
    "def create_x_y(left_branch, right_branch):\n",
    "    X_left = left_branch.drop('IDAP', axis=1)\n",
    "    Y_left = left_branch['IDAP']\n",
    "    X_right = right_branch.drop('IDAP', axis=1)\n",
    "    Y_right = right_branch['IDAP']\n",
    "    return X_left, Y_left, X_right, Y_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define custom splitter function\n",
    "def specify_split(X, Y, feature):\n",
    "    X_first_split = X[[feature]]\n",
    "    dtc =  DTC(random_state=123, max_depth=1)\n",
    "    dt_model = dtc.fit(X_first_split, Y)\n",
    "    optimal_split = dt_model.tree_.threshold[0]\n",
    "    data = pd.DataFrame(Y).join(X)\n",
    "    left_branch = data[data[feature] <= optimal_split]\n",
    "    right_branch = data[data[feature] > optimal_split]\n",
    "    return left_branch, right_branch, dt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_webgraph_top(tree, feature_name, outfile_name):\n",
    "\n",
    "    tree_ = tree.tree_\n",
    "#     feature_name = [\n",
    "#         feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "#         for i in tree_.feature]\n",
    "\n",
    "    f = open(outfile_name, \"w+\")\n",
    "    f.write('digraph Tree {\\n')\n",
    "    f.write('node [shape=box, style=\"filled, rounded\", color=\"black\", fontname=helvetica] ;\\n')\n",
    "    f.write('edge [fontname=helvetica] ;\\n')\n",
    "    \n",
    "    for node in range(len(tree_.feature)):\n",
    "        name = feature_name[node]\n",
    "        threshold = round(tree_.threshold[node], 2)\n",
    "        impurity = round(tree_.impurity[node], 2)\n",
    "        values = tree_.value[node][0]\n",
    "        \n",
    "        if np.argmax(tree_.value[node][0]) == 0:\n",
    "            label = 'H'\n",
    "            color = '#e5813938'\n",
    "        elif np.argmax(tree_.value[node][0]) == 1:\n",
    "            label = 'M'\n",
    "            color = '#39e581c6'\n",
    "        else:\n",
    "            label = 'NM'\n",
    "            color = '#8139e579'\n",
    "            \n",
    "        \n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            f.write('{} [label=\"{} <= {}\\\\ngini = {}\\\\nvalue = {}\\\\nclass = {}\", fillcolor=\"{}\"] ;\\n'.format(node, feature_name, threshold, impurity, values, label, color)) \n",
    "            f.write('{} -> {} [labeldistance=2.5, labelangle=45, headlabel=\"True\"] ;\\n'.format(node, tree_.children_left[node]))\n",
    "            f.write('{} -> {} [labeldistance=2.5, labelangle=-45, headlabel=\"False\"] ;\\n'.format(node, tree_.children_right[node]))\n",
    "            left_node = tree_.children_left[node]\n",
    "            right_node = tree_.children_right[node]\n",
    "\n",
    "    f.close()\n",
    "    max_node = max(range(len(tree_.feature)))\n",
    "    return left_node, right_node, max_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tree_to_webgraph_second(tree, feature_name, node, max_node, outfile_name, end=False):\n",
    "\n",
    "    tree_ = tree.tree_\n",
    "    \n",
    "    node_list = [i + max_node+1 for i in range(len(tree_.feature))]\n",
    "    node_list[0] = node\n",
    "    f = open(outfile_name, \"a+\")\n",
    "        \n",
    "    for node_name, node_index in zip(node_list, range(len(tree_.feature))):\n",
    "        threshold = round(tree_.threshold[node_index], 2)\n",
    "        impurity = round(tree_.impurity[node_index], 2)\n",
    "        values = tree_.value[node_index][0]\n",
    "        \n",
    "        if np.argmax(tree_.value[node_index][0]) == 0:\n",
    "            label = 'H'\n",
    "            color = '#e5813938'\n",
    "        elif np.argmax(tree_.value[node_index][0]) == 1:\n",
    "            label = 'M'\n",
    "            color = '#39e581c6'\n",
    "        else:\n",
    "            label = 'NM'\n",
    "            color = '#8139e579'\n",
    "        \n",
    "        if tree_.feature[node_index] != _tree.TREE_UNDEFINED:\n",
    "            f.write('{} [label=\"{} <= {}\\\\ngini = {}\\\\nvalue = {}\\\\nclass = {}\", fillcolor=\"{}\"] ;\\n'.format(node_name, feature_name, threshold, impurity, values, label, color)) \n",
    "            f.write('{} -> {} ;\\n'.format(node_name, tree_.children_left[node_index]+max_node+1))\n",
    "            f.write('{} -> {} ;\\n'.format(node_name, tree_.children_right[node_index]+max_node+1))\n",
    "            left_node = tree_.children_left[node_index] + max_node+1\n",
    "            right_node = tree_.children_right[node_index] + max_node+1\n",
    "\n",
    "    if end == True:\n",
    "        f.write('}')\n",
    "    max_node = max(node_list)\n",
    "    f.close()\n",
    "    return left_node, right_node, max_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_webgraph_bottom(tree, feature_names, node, max_node, outfile_name, end=False):\n",
    "\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature]\n",
    "    \n",
    "    node_list = [i + max_node+1 for i in range(len(tree_.feature))]\n",
    "    node_list[0] = node\n",
    "    f = open(outfile_name, \"a+\")\n",
    "    \n",
    "    feature_name_dict = {}\n",
    "    for node, feature in zip(node_list, feature_name):\n",
    "        feature_name_dict[node] = feature \n",
    "        \n",
    "    for node_name, node_index in zip(node_list, range(len(tree_.feature))):\n",
    "        name = feature_name_dict[node_name]\n",
    "        threshold = round(tree_.threshold[node_index], 2)\n",
    "        impurity = round(tree_.impurity[node_index], 2)\n",
    "        values = tree_.value[node_index][0]\n",
    "        \n",
    "        if np.argmax(tree_.value[node_index][0]) == 0:\n",
    "            label = 'H'\n",
    "            color = '#e5813938'\n",
    "        elif np.argmax(tree_.value[node_index][0]) == 1:\n",
    "            label = 'M'\n",
    "            color = '#39e581c6'\n",
    "        else:\n",
    "            label = 'NM'\n",
    "            color = '#8139e579'\n",
    "        \n",
    "        if tree_.feature[node_index] != _tree.TREE_UNDEFINED:\n",
    "            f.write('{} [label=\"{} <= {}\\\\ngini = {}\\\\nvalue = {}\\\\nclass = {}\", fillcolor=\"{}\"] ;\\n'.format(node_name, name, threshold, impurity, values, label, color)) \n",
    "            f.write('{} -> {} ;\\n'.format(node_name, tree_.children_left[node_index]+max_node+1))\n",
    "            f.write('{} -> {} ;\\n'.format(node_name, tree_.children_right[node_index]+max_node+1))\n",
    "        else:\n",
    "            f.write('{} [label=\"gini = {}\\\\nvalue = {}\\\\nclass = {}\", fillcolor=\"{}\"] ;\\n'.format(node_name, impurity, values, label, color))\n",
    "    \n",
    "    if end == True:\n",
    "        f.write('}')\n",
    "    if len(tree_.feature) == 1:\n",
    "        max_node = max_node + 1\n",
    "    else:\n",
    "        max_node = max(node_list)\n",
    "    f.close()\n",
    "    return max_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specify_dtc(X, Y, split_hierarchy, max_leaf_nodes, outfile_name, num_splits):\n",
    "    if num_splits == 4:\n",
    "        ######################\n",
    "        #### First split #####\n",
    "        ######################\n",
    "        left, right, dt_first = specify_split(X, Y, split_hierarchy.loc['first'][0])\n",
    "        X_left, Y_left, X_right, Y_right = create_x_y(left, right)\n",
    "        left_node, right_node, max_node = tree_to_webgraph_top(dt_first, split_hierarchy.loc['first'][0], outfile_name)\n",
    "\n",
    "        ######################\n",
    "        #### Second Split ####\n",
    "        ######################\n",
    "        # Split left branch\n",
    "        left_left, left_right, dt_left = specify_split(X_left, Y_left, split_hierarchy.loc['left'][0])\n",
    "        X_left_left, Y_left_left, X_left_right, Y_left_right = create_x_y(left_left, left_right)\n",
    "        left_left_node, left_right_node, max_node = tree_to_webgraph_second(dt_left, split_hierarchy.loc['left'][0], left_node, max_node, outfile_name)\n",
    "\n",
    "        # Split right branch\n",
    "        right_left, right_right, dt_right = specify_split(X_right, Y_right, split_hierarchy.loc['right'][0])\n",
    "        X_right_left, Y_right_left, X_right_right, Y_right_right = create_x_y(right_left, right_right)\n",
    "        right_left_node, right_right_node, max_node = tree_to_webgraph_second(dt_right, split_hierarchy.loc['right'][0], right_node, max_node, outfile_name)\n",
    "\n",
    "        ######################\n",
    "        #### Third Split #####\n",
    "        ######################\n",
    "        ## Left Branch ##\n",
    "        # Split left_left branch\n",
    "        left_left_left, left_left_right, dt_left_left = specify_split(X_left_left, Y_left_left, split_hierarchy.loc['left_left'][0])\n",
    "        X_left_left_left, Y_left_left_left, X_left_left_right, Y_left_left_right = create_x_y(left_left_left, left_left_right)\n",
    "        left_left_left_node, left_left_right_node, max_node = tree_to_webgraph_second(dt_left_left, split_hierarchy.loc['left_left'][0], left_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Split left_right branch\n",
    "        left_right_left, left_right_right, dt_left_right = specify_split(X_left_right, Y_left_right, split_hierarchy.loc['left_right'][0])\n",
    "        X_left_right_left, Y_left_right_left, X_left_right_right, Y_left_right_right = create_x_y(left_right_left, left_right_right)\n",
    "        left_right_left_node, left_right_right_node, max_node = tree_to_webgraph_second(dt_left_right, split_hierarchy.loc['left_right'][0], left_right_node, max_node, outfile_name)\n",
    "\n",
    "        ## Right Branch ##\n",
    "        # Split right_left branch\n",
    "        right_left_left, right_left_right, dt_right_left = specify_split(X_right_left, Y_right_left, split_hierarchy.loc['right_left'][0])\n",
    "        X_right_left_left, Y_right_left_left, X_right_left_right, Y_right_left_right = create_x_y(right_left_left, right_left_right)\n",
    "        right_left_left_node, right_left_right_node, max_node = tree_to_webgraph_second(dt_right_left, split_hierarchy.loc['right_left'][0], right_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Split right_right branch\n",
    "        right_right_left, right_right_right, dt_right_right = specify_split(X_right_right, Y_right_right, split_hierarchy.loc['right_right'][0])\n",
    "        X_right_right_left, Y_right_right_left, X_right_right_right, Y_right_right_right = create_x_y(right_right_left, right_right_right)\n",
    "        right_right_left_node, right_right_right_node, max_node = tree_to_webgraph_second(dt_right_right, split_hierarchy.loc['right_right'][0], right_right_node, max_node, outfile_name)\n",
    "\n",
    "        ######################\n",
    "        #### Fourth Split ####\n",
    "        ######################\n",
    "        ## Left_Left Branch ##\n",
    "        # Split left_left_left branch\n",
    "        left_left_left_left, left_left_left_right, dt_left_left_left = specify_split(X_left_left_left, Y_left_left_left, split_hierarchy.loc['left_left_left'][0])\n",
    "        X_left_left_left_left, Y_left_left_left_left, X_left_left_left_right, Y_left_left_left_right = create_x_y(left_left_left_left, left_left_left_right)\n",
    "        left_left_left_left_node, left_left_left_right_node, max_node = tree_to_webgraph_second(dt_left_left_left, split_hierarchy.loc['left_left_left'][0], left_left_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Split left_left_right branch\n",
    "        left_left_right_left, left_left_right_right, dt_left_left_right = specify_split(X_left_left_right, Y_left_left_right, split_hierarchy.loc['left_left_right'][0])\n",
    "        X_left_left_right_left, Y_left_left_right_left, X_left_left_right_right, Y_left_left_right_right = create_x_y(left_left_right_left, left_left_right_right)\n",
    "        left_left_right_left_node, left_left_right_right_node, max_node = tree_to_webgraph_second(dt_left_left_right, split_hierarchy.loc['left_left_right'][0], left_left_right_node, max_node, outfile_name)\n",
    "\n",
    "        ## Left_Right Branch ##\n",
    "        # Split left_right_left branch\n",
    "        left_right_left_left, left_right_left_right, dt_left_right_left = specify_split(X_left_right_left, Y_left_right_left, split_hierarchy.loc['left_right_left'][0])\n",
    "        X_left_right_left_left, Y_left_right_left_left, X_left_right_left_right, Y_left_right_left_right = create_x_y(left_right_left_left, left_right_left_right)\n",
    "        left_right_left_left_node, left_right_left_right_node, max_node = tree_to_webgraph_second(dt_left_right_left, split_hierarchy.loc['left_right_left'][0], left_right_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Split left_right_right branch\n",
    "        left_right_right_left, left_right_right_right, dt_left_right_right = specify_split(X_left_right_right, Y_left_right_right, split_hierarchy.loc['left_right_right'][0])\n",
    "        X_left_right_right_left, Y_left_right_right_left, X_left_right_right_right, Y_left_right_right_right = create_x_y(left_right_right_left, left_right_right_right)\n",
    "        left_right_right_left_node, left_right_right_right_node, max_node = tree_to_webgraph_second(dt_left_right_right, split_hierarchy.loc['left_right_right'][0], left_right_right_node, max_node, outfile_name)\n",
    "\n",
    "        ## Right_Left Branch ##\n",
    "        # Split right_left_left branch\n",
    "        right_left_left_left, right_left_left_right, dt_right_left_left = specify_split(X_right_left_left, Y_right_left_left, split_hierarchy.loc['right_left_left'][0])\n",
    "        X_right_left_left_left, Y_right_left_left_left, X_right_left_left_right, Y_right_left_left_right = create_x_y(right_left_left_left, right_left_left_right)\n",
    "        right_left_left_left_node, right_left_left_right_node, max_node = tree_to_webgraph_second(dt_right_left_left, split_hierarchy.loc['right_left_left'][0], right_left_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Split right_left_right branch\n",
    "        right_left_right_left, right_left_right_right, dt_right_left_right = specify_split(X_right_left_right, Y_right_left_right, split_hierarchy.loc['right_left_right'][0])\n",
    "        X_right_left_right_left, Y_right_left_right_left, X_right_left_right_right, Y_right_left_right_right = create_x_y(right_left_right_left, right_left_right_right)\n",
    "        right_left_right_left_node, right_left_right_right_node, max_node = tree_to_webgraph_second(dt_right_left_right, split_hierarchy.loc['right_left_right'][0], right_left_right_node, max_node, outfile_name)\n",
    "\n",
    "        ## Right_Right Branch ##\n",
    "        # Split right_right_left branch\n",
    "        right_right_left_left, right_right_left_right, dt_right_right_left = specify_split(X_right_right_left, Y_right_right_left, split_hierarchy.loc['right_right_left'][0])\n",
    "        X_right_right_left_left, Y_right_right_left_left, X_right_right_left_right, Y_right_right_left_right = create_x_y(right_right_left_left, right_right_left_right)\n",
    "        right_right_left_left_node, right_right_left_right_node, max_node = tree_to_webgraph_second(dt_right_right_left, split_hierarchy.loc['right_right_left'][0], right_right_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Split right_right_right branch\n",
    "        right_right_right_left, right_right_right_right, dt_right_right_right = specify_split(X_right_right_right, Y_right_right_right, split_hierarchy.loc['right_right_right'][0])\n",
    "        X_right_right_right_left, Y_right_right_right_left, X_right_right_right_right, Y_right_right_right_right = create_x_y(right_right_right_left, right_right_right_right)\n",
    "        right_right_right_left_node, right_right_right_right_node, max_node = tree_to_webgraph_second(dt_right_right_right, split_hierarchy.loc['right_right_right'][0], right_right_right_node, max_node, outfile_name)\n",
    "\n",
    "        ##########################################\n",
    "        #### Train subsequent bottom of trees ####\n",
    "        ##########################################\n",
    "        dtc =  DTC(random_state=123, max_leaf_nodes=max_leaf_nodes)\n",
    "\n",
    "        #### Train Bottom Trees ####\n",
    "        ## Left Left left Branch ##\n",
    "        # Train classifier left left left left\n",
    "        dt_left_left_left_left = dtc.fit(X_left_left_left_left, Y_left_left_left_left)\n",
    "        max_node = tree_to_webgraph_bottom(dt_left_left_left_left, X.columns, left_left_left_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Train classifier left left left right\n",
    "        dt_left_left_left_right = dtc.fit(X_left_left_left_right, Y_left_left_left_right)\n",
    "        max_node = tree_to_webgraph_bottom(dt_left_left_left_right, X.columns, left_left_left_right_node, max_node, outfile_name)\n",
    "\n",
    "        ## Left Left Right Branch ##\n",
    "        # Train classifier left left right left\n",
    "        dt_left_left_right_left = dtc.fit(X_left_left_right_left, Y_left_left_right_left)\n",
    "        max_node = tree_to_webgraph_bottom(dt_left_left_right_left, X.columns, left_left_right_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Train classifier left left right right\n",
    "        dt_left_left_right_right = dtc.fit(X_left_left_right_right, Y_left_left_right_right)\n",
    "        max_node = tree_to_webgraph_bottom(dt_left_left_right_right, X.columns, left_left_right_right_node, max_node, outfile_name)\n",
    "\n",
    "        ## Left Right Left Branch ##\n",
    "        # Train classifier left right left left\n",
    "        dt_left_right_left_left = dtc.fit(X_left_right_left_left, Y_left_right_left_left)\n",
    "        max_node = tree_to_webgraph_bottom(dt_left_right_left_left, X.columns, left_right_left_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Train classifier left right left right\n",
    "        dt_left_right_left_right = dtc.fit(X_left_right_left_right, Y_left_right_left_right)\n",
    "        max_node = tree_to_webgraph_bottom(dt_left_right_left_right, X.columns, left_right_left_right_node, max_node, outfile_name)\n",
    "\n",
    "        ## Left Right Right Branch ##\n",
    "        # Train classifier left right right left\n",
    "        dt_left_right_right_left = dtc.fit(X_left_right_right_left, Y_left_right_right_left)\n",
    "        max_node = tree_to_webgraph_bottom(dt_left_right_right_left, X.columns, left_right_right_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Train classifier left right right right\n",
    "        dt_left_right_right_right = dtc.fit(X_left_right_right_right, Y_left_right_right_right)\n",
    "        max_node = tree_to_webgraph_bottom(dt_left_right_right_right, X.columns, left_right_right_right_node, max_node, outfile_name)\n",
    "\n",
    "        ## Right Left Left Branch ##\n",
    "        # Train classifier right left left left\n",
    "        dt_right_left_left_left = dtc.fit(X_right_left_left_left, Y_right_left_left_left)\n",
    "        max_node = tree_to_webgraph_bottom(dt_right_left_left_left, X.columns, right_left_left_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Train classifier right left left right\n",
    "        dt_right_left_left_right = dtc.fit(X_right_left_left_right, Y_right_left_left_right)\n",
    "        max_node = tree_to_webgraph_bottom(dt_right_left_left_right, X.columns, right_left_left_right_node, max_node, outfile_name)\n",
    "\n",
    "        ## Right Left Right Branch ##\n",
    "        # Train classifier right left right left\n",
    "        dt_right_left_right_left = dtc.fit(X_right_left_right_left, Y_right_left_right_left)\n",
    "        max_node = tree_to_webgraph_bottom(dt_right_left_right_left, X.columns, right_left_right_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Train classifier right left right right\n",
    "        dt_right_left_right_right = dtc.fit(X_right_left_right_right, Y_right_left_right_right)\n",
    "        max_node = tree_to_webgraph_bottom(dt_right_left_right_right, X.columns, right_left_right_right_node, max_node, outfile_name)\n",
    "\n",
    "        ## Right Right Left Branch ##\n",
    "        # Train classifier right right left left\n",
    "        dt_right_right_left_left = dtc.fit(X_right_right_left_left, Y_right_right_left_left)\n",
    "        max_node = tree_to_webgraph_bottom(dt_right_right_left_left, X.columns, right_right_left_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Train classifier right right left right\n",
    "        dt_right_right_left_right = dtc.fit(X_right_right_left_right, Y_right_right_left_right)\n",
    "        max_node = tree_to_webgraph_bottom(dt_right_right_left_right, X.columns, right_right_left_right_node, max_node, outfile_name)\n",
    "\n",
    "        ## Right Right Right Branch ##\n",
    "        # Train classifier right right right left\n",
    "        dt_right_right_right_left = dtc.fit(X_right_right_right_left, Y_right_right_right_left)\n",
    "        max_node = tree_to_webgraph_bottom(dt_right_right_right_left, X.columns, right_right_right_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Train classifier right right right right\n",
    "        dt_right_right_right_right = dtc.fit(X_right_right_right_right, Y_right_right_right_right)\n",
    "        max_node = tree_to_webgraph_bottom(dt_right_right_right_right, X.columns, right_right_right_right_node, max_node, outfile_name, end=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    elif num_splits == 3:\n",
    "        ######################\n",
    "        #### First split #####\n",
    "        ######################\n",
    "        left, right, dt_first = specify_split(X, Y, split_hierarchy.loc['first'][0])\n",
    "        X_left, Y_left, X_right, Y_right = create_x_y(left, right)\n",
    "        left_node, right_node, max_node = tree_to_webgraph_top(dt_first, split_hierarchy.loc['first'][0], outfile_name)\n",
    "\n",
    "        ######################\n",
    "        #### Second Split ####\n",
    "        ######################\n",
    "        # Split left branch\n",
    "        left_left, left_right, dt_left = specify_split(X_left, Y_left, split_hierarchy.loc['left'][0])\n",
    "        X_left_left, Y_left_left, X_left_right, Y_left_right = create_x_y(left_left, left_right)\n",
    "        left_left_node, left_right_node, max_node = tree_to_webgraph_second(dt_left, split_hierarchy.loc['left'][0], left_node, max_node, outfile_name)\n",
    "\n",
    "        # Split right branch\n",
    "        right_left, right_right, dt_right = specify_split(X_right, Y_right, split_hierarchy.loc['right'][0])\n",
    "        X_right_left, Y_right_left, X_right_right, Y_right_right = create_x_y(right_left, right_right)\n",
    "        right_left_node, right_right_node, max_node = tree_to_webgraph_second(dt_right, split_hierarchy.loc['right'][0], right_node, max_node, outfile_name)\n",
    "\n",
    "        ######################\n",
    "        #### Third Split #####\n",
    "        ######################\n",
    "        ## Left Branch ##\n",
    "        # Split left_left branch\n",
    "        left_left_left, left_left_right, dt_left_left = specify_split(X_left_left, Y_left_left, split_hierarchy.loc['left_left'][0])\n",
    "        X_left_left_left, Y_left_left_left, X_left_left_right, Y_left_left_right = create_x_y(left_left_left, left_left_right)\n",
    "        left_left_left_node, left_left_right_node, max_node = tree_to_webgraph_second(dt_left_left, split_hierarchy.loc['left_left'][0], left_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Split left_right branch\n",
    "        left_right_left, left_right_right, dt_left_right = specify_split(X_left_right, Y_left_right, split_hierarchy.loc['left_right'][0])\n",
    "        X_left_right_left, Y_left_right_left, X_left_right_right, Y_left_right_right = create_x_y(left_right_left, left_right_right)\n",
    "        left_right_left_node, left_right_right_node, max_node = tree_to_webgraph_second(dt_left_right, split_hierarchy.loc['left_right'][0], left_right_node, max_node, outfile_name)\n",
    "\n",
    "        ## Right Branch ##\n",
    "        # Split right_left branch\n",
    "        right_left_left, right_left_right, dt_right_left = specify_split(X_right_left, Y_right_left, split_hierarchy.loc['right_left'][0])\n",
    "        X_right_left_left, Y_right_left_left, X_right_left_right, Y_right_left_right = create_x_y(right_left_left, right_left_right)\n",
    "        right_left_left_node, right_left_right_node, max_node = tree_to_webgraph_second(dt_right_left, split_hierarchy.loc['right_left'][0], right_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Split right_right branch\n",
    "        right_right_left, right_right_right, dt_right_right = specify_split(X_right_right, Y_right_right, split_hierarchy.loc['right_right'][0])\n",
    "        X_right_right_left, Y_right_right_left, X_right_right_right, Y_right_right_right = create_x_y(right_right_left, right_right_right)\n",
    "        right_right_left_node, right_right_right_node, max_node = tree_to_webgraph_second(dt_right_right, split_hierarchy.loc['right_right'][0], right_right_node, max_node, outfile_name)\n",
    "\n",
    "        ##########################################\n",
    "        #### Train subsequent bottom of trees ####\n",
    "        ##########################################\n",
    "        dtc =  DTC(random_state=123, max_leaf_nodes=max_leaf_nodes)\n",
    "\n",
    "        #### Train Bottom Trees ####\n",
    "        ## Left Left Branch ##\n",
    "        # Train classifier left left left\n",
    "        dt_left_left_left = dtc.fit(X_left_left_left, Y_left_left_left)\n",
    "        max_node = tree_to_webgraph_bottom(dt_left_left_left, X.columns, left_left_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Train classifier left left right\n",
    "        dt_left_left_right = dtc.fit(X_left_left_right, Y_left_left_right)\n",
    "        max_node = tree_to_webgraph_bottom(dt_left_left_right, X.columns, left_left_right_node, max_node, outfile_name)\n",
    "\n",
    "        ## Left Right Branch ##\n",
    "        # Train classifier left right left\n",
    "        dt_left_right_left = dtc.fit(X_left_right_left, Y_left_right_left)\n",
    "        max_node = tree_to_webgraph_bottom(dt_left_right_left, X.columns, left_right_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Train classifier left right right\n",
    "        dt_left_right_right = dtc.fit(X_left_right_right, Y_left_right_right)\n",
    "        max_node = tree_to_webgraph_bottom(dt_left_right_right, X.columns, left_right_right_node, max_node, outfile_name)\n",
    "\n",
    "        ## Right Left Branch ##\n",
    "        # Train classifier right left left\n",
    "        dt_right_left_left = dtc.fit(X_right_left_left, Y_right_left_left)\n",
    "        max_node = tree_to_webgraph_bottom(dt_right_left_left, X.columns, right_left_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Train classifier right left right\n",
    "        dt_right_left_right = dtc.fit(X_right_left_right, Y_right_left_right)\n",
    "        max_node = tree_to_webgraph_bottom(dt_right_left_right, X.columns, right_left_right_node, max_node, outfile_name)\n",
    "\n",
    "        ## Right Right Branch ##\n",
    "        # Train classifier right right left\n",
    "        dt_right_right_left = dtc.fit(X_right_right_left, Y_right_right_left)\n",
    "        max_node = tree_to_webgraph_bottom(dt_right_right_left, X.columns, right_right_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Train classifier right right right\n",
    "        dt_right_right_right = dtc.fit(X_right_right_right, Y_right_right_right)\n",
    "        max_node = tree_to_webgraph_bottom(dt_right_right_right, X.columns, right_right_right_node, max_node, outfile_name, end=True)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    elif num_splits == 2:\n",
    "        ######################\n",
    "        #### First split #####\n",
    "        ######################\n",
    "        left, right, dt_first = specify_split(X, Y, split_hierarchy.loc['first'][0])\n",
    "        X_left, Y_left, X_right, Y_right = create_x_y(left, right)\n",
    "        left_node, right_node, max_node = tree_to_webgraph_top(dt_first, split_hierarchy.loc['first'][0], outfile_name)\n",
    "\n",
    "        ######################\n",
    "        #### Second Split ####\n",
    "        ######################\n",
    "        # Split left branch\n",
    "        left_left, left_right, dt_left = specify_split(X_left, Y_left, split_hierarchy.loc['left'][0])\n",
    "        X_left_left, Y_left_left, X_left_right, Y_left_right = create_x_y(left_left, left_right)\n",
    "        left_left_node, left_right_node, max_node = tree_to_webgraph_second(dt_left, split_hierarchy.loc['left'][0], left_node, max_node, outfile_name)\n",
    "\n",
    "        # Split right branch\n",
    "        right_left, right_right, dt_right = specify_split(X_right, Y_right, split_hierarchy.loc['right'][0])\n",
    "        X_right_left, Y_right_left, X_right_right, Y_right_right = create_x_y(right_left, right_right)\n",
    "        right_left_node, right_right_node, max_node = tree_to_webgraph_second(dt_right, split_hierarchy.loc['right'][0], right_node, max_node, outfile_name)\n",
    "\n",
    "        ##########################################\n",
    "        #### Train subsequent bottom of trees ####\n",
    "        ##########################################\n",
    "        dtc =  DTC(random_state=123, max_leaf_nodes=max_leaf_nodes)\n",
    "\n",
    "        #### Train Bottom Trees ####\n",
    "        ## Left Branch ##\n",
    "        # Train classifier left left\n",
    "        dt_left_left = dtc.fit(X_left_left, Y_left_left)\n",
    "        max_node = tree_to_webgraph_bottom(dt_left_left, X.columns, left_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Train classifier left right\n",
    "        dt_left_right = dtc.fit(X_left_right, Y_left_right)\n",
    "        max_node = tree_to_webgraph_bottom(dt_left_right, X.columns, left_right_node, max_node, outfile_name)\n",
    "\n",
    "        ## Right Branch ##\n",
    "        # Train classifier right left\n",
    "        dt_right_left = dtc.fit(X_right_left, Y_right_left)\n",
    "        max_node = tree_to_webgraph_bottom(dt_right_left, X.columns, right_left_node, max_node, outfile_name)\n",
    "\n",
    "        # Train classifier right right\n",
    "        dt_right_right = dtc.fit(X_right_right, Y_right_right)\n",
    "        max_node = tree_to_webgraph_bottom(dt_right_right, X.columns, right_right_node, max_node, outfile_name, end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select only specific person types\n",
    "features_pertype = features[(features['PERTYPE'] == 'PDA_Stud') | (features['PERTYPE'] == 'DA_Stud')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and Y\n",
    "X = features_pertype[['AGE', 'JOBS', 'DIST', 'ACCESSIBILITY', 'CAR_SUFF', 'HINCCAT1']]\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "#X.drop(['GENDER_Male'], axis=1, inplace=True)\n",
    "Y = features_pertype['IDAP']\n",
    "dtc =  DTC(random_state=234, max_leaf_nodes=6)\n",
    "dt_model = dtc.fit(X, Y)\n",
    "with open(\"dt_test_6_7.txt\", \"w\") as f:\n",
    "    f = tree.export_graphviz(dt_model, out_file=f, feature_names=X.columns, \n",
    "                             class_names=['H','M','NM'],\n",
    "                             rounded=True,\n",
    "                             filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Retiree', 'FT_Worker', 'PT_Worker', 'DA_Stud', 'PreSch_Child',\n",
       "       'PDA_Stud', 'Non_Worker', 'Univ_Stud'], dtype=object)"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.PERTYPE.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SAMPN', 'PERNO', 'GENDER', 'PERTYPE', 'AGE', 'IDAP', 'CAR_SUFF',\n",
       "       'HINCCAT1', 'EDUCA', 'JOBS', 'JOBTYPE', 'ACCESSIBILITY', 'DIST',\n",
       "       'Retiree_NM', 'Retiree_M', 'Retiree_H', 'FT_Worker_NM', 'FT_Worker_M',\n",
       "       'FT_Worker_H', 'PT_Worker_NM', 'PT_Worker_M', 'PT_Worker_H',\n",
       "       'DA_Stud_NM', 'DA_Stud_M', 'DA_Stud_H', 'PreSch_Child_NM',\n",
       "       'PreSch_Child_M', 'PreSch_Child_H', 'PDA_Stud_NM', 'PDA_Stud_M',\n",
       "       'PDA_Stud_H', 'Non_Worker_NM', 'Non_Worker_M', 'Non_Worker_H',\n",
       "       'Univ_Stud_NM', 'Univ_Stud_M', 'Univ_Stud_H'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select only specific person types\n",
    "features_pertype = features[(features['PERTYPE'] == 'PDA_Stud') | (features['PERTYPE'] == 'DA_Stud')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and Y\n",
    "X = features_pertype[['AGE', 'JOBS', 'DIST', 'ACCESSIBILITY', 'CAR_SUFF', 'HINCCAT1']]\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "#X.drop(['GENDER_Male'], axis=1, inplace=True)\n",
    "Y = features_pertype['IDAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read split hierarchy\n",
    "split_hierarchy = pd.read_csv('split_hierarchy.csv', index_col=0)\n",
    "max_leaf_nodes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run dtc with specified contraints\n",
    "specify_dtc(X, Y, split_hierarchy, max_leaf_nodes, 'dt_pertype_6_7.txt', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
